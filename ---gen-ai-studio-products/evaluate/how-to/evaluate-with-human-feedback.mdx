---
title: "Evaluate With Human Feedback"
---

# Evaluate with Human Feedback

Galileo allows you to do qualitative human evaluations of your prompts and responses.

**Configure your Human Ratings settings**

You can configure your Human Ratings settings by clicking on "Configure Human Ratings" from your Project or Run view. Your configuration is applied to all runs in the Project, to allow you to compare all runs on the same rating dimensions.

You can configure multiple dimensions or "Rating Types" to rate your run on. Each Rating Type will be used to rate your responses on a different dimension (e.g. quality, conciseness, hallucination potential, etc).

Types are Name and have a Format. We support 5 formats:

*   üëç/ üëé
    
*   1 - 5 ‚≠ês
    
*   Numerical ratings
    
*   Categorical ratings (self-defined categories)
    
*   Free-form text
    

Along with each rating, you can also allow raters to provide a rationale.

To align everyone on the Rating Criteria or rubric, you can define it as part of your Human Ratings configuration.

![](https://docs.rungalileo.io/~gitbook/image?url=https%3A%2F%2F1924900477-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F4jVWiQpRqmi04OnqZmn2%252Fuploads%252FNdKhnPbfLSSVM8cXg3fG%252Fimage.png%3Falt%3Dmedia%26token%3D1034cdfc-6010-4c93-8650-b57f92ca3c83&width=768&dpr=4&quality=100&sign=66ce77f7&sv=1)

**Adding Ratings**

Add your Ratings from the _Feedback_ tab of your Trace or Expanded View.

Note: Ratings on Chains or Workflows apply to the entire chain (not just the Node in view).

![](https://docs.rungalileo.io/~gitbook/image?url=https%3A%2F%2F1924900477-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F4jVWiQpRqmi04OnqZmn2%252Fuploads%252FLVX2hpgMf0qrltp7W9ed%252Fimage.png%3Falt%3Dmedia%26token%3D33dae250-e64d-41af-be0e-080ac8f9d9d8&width=768&dpr=4&quality=100&sign=b5c40265&sv=1)

[PreviousExperiment with Multiple Chain Workflows](/galileo/gen-ai-studio-products/galileo-evaluate/how-to/chain-sweeps)[NextAdd Tags and Metadata to Prompt Runs](/galileo/gen-ai-studio-products/galileo-evaluate/how-to/adding-tags-to-prompt-runs)

Last updated 3 months ago