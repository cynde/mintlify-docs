---
title: "Actions"
---

# Actions

![](https://docs.rungalileo.io/~gitbook/image?url=https%3A%2F%2F1924900477-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F4jVWiQpRqmi04OnqZmn2%252Fuploads%252FxLfisSkryhcjzjZaXxcY%252Fezgif.com-video-to-gif%2520%283%29.gif%3Falt%3Dmedia%26token%3D4486245c-3912-427c-9126-b6217799d842&width=768&dpr=4&quality=100&sign=17d37e49&sv=1)

Actions help close the inspection loop and error discovery process. We support a number of actions. Generally these actions fall under two categories:

1) Fixing data in-tool:

*   Edit Data
    
*   Remove
    
*   Change Label
    

2) Exporting Data to fix it elsewhere:

*   Send to Labelers
    
*   Export Data
    

### 

[](#fixing-data-in-tool)

**Fixing Data In-Tool**

**Edit Data**

This feature is only supported for NLP tasks. Through _Edit Data_ you can quickly make small changes to your text samples. For Classification tasks, you can find and replace text (indivually or in bulk). For NER tasks, you can also use _Edit Data_ to shift spans, add new spans or remove spans.

**Removing Data**

Sometimes you find data samples that simply shouldn't be part of your dataset (e.g. garbage data) or simply want to remove mislabeled samples from your training dataset. "Remove data" allows you to remove these samples from your dataset. Upon selecting some samples, you'll have the option to remove them. Removed samples go to your Edits Cart, from where you can download your "fixed" dataset to train another model iteration.

**Change Label**

For Classification tasks, _Change Label_ allows you to change the label of you selected samples. You can either set the label to what the model predicted or manually enter the label you'd like these samples to have.

### 

[](#exporting-data-to-fix-it-elsewhere)

**Exporting Data to fix it elsewhere**

At any point in the inspection process you can export any selection of data. You can download your data as a CSV, download to an S3, GCS or DeltaLake bucket, or programmatically fetch it through <span title="Broken link" class="underline"><code class="py-[1px] px-1.5 min-w-[1.625rem] inline-flex justify-center items-center ring-1 ring-inset ring-dark/1 bg-dark/[0.06] rounded text-dark/8 dark:ring-light/1 dark:bg-light/1 dark:text-light/7 text-[.875em] leading-[calc(max(1.20em,1.25rem))]">dq.metrics</code></span><code class="py-[1px] px-1.5 min-w-[1.625rem] inline-flex justify-center items-center ring-1 ring-inset ring-dark/1 bg-dark/[0.06] rounded text-dark/8 dark:ring-light/1 dark:bg-light/1 dark:text-light/7 text-[.875em] leading-[calc(max(1.20em,1.25rem))]"></code>

Additionally, after taking actions like the ones mentioned above, your Changes will show up on the Edits Cart. From there you can export your full dataset (including or excluding changes) to train a new model run.

**Send to Labelers**

Sometimes you want your labelers to fix your data. Once you've identified a cohort of data that is mislabeled, you can use the _Send to Labelers_ button and leverage our labeling integrations to send your samples to your labeling provider in one click.

[PreviousDataset Slices](/galileo/how-to-and-faq/galileo-product-features/dataset-slices)[NextCompare across Runs](/galileo/how-to-and-faq/galileo-product-features/compare-across-runs)

Last updated 1 year ago