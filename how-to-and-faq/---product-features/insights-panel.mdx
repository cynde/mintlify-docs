---
title: "Insights Panel"
---

# Insights Panel

Galileo provides a dynamic _Insights Panel_ that provides a bird's eye view of your model's performance on the data currently in scope. Specifically, the Insights Panel contains three sections:

*   [Alerts](/galileo/how-to-and-faq/galileo-product-features/xray-insights)
    
*   Metrics (see below)
    
*   [Clusters](/galileo/how-to-and-faq/galileo-product-features/clusters)
    

**Metrics**

Under the "Metrics" tab you can find a number of charts and insights that update dynamically. Through these charts you can get greater insights into the subset of data you're currently looking at. These content of these charts differ depending on the task type. Generally, they include

*   Overall model and dataset metrics
    
*   Class level model performance
    
*   Class level DEP scores
    
*   Class distributions
    
*   Top most misclassified pairs
    
*   Error distributions
    
*   Class Overlap
    

The Insights Panel allows you to keep a constant check on model performance as you continue the inspection process (through the [Dataset View](/galileo/how-to-and-faq/galileo-product-features/dataset-view) and [Embeddings View](/galileo/how-to-and-faq/galileo-product-features/embeddings-view)).

![](https://docs.rungalileo.io/~gitbook/image?url=https%3A%2F%2F1924900477-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F4jVWiQpRqmi04OnqZmn2%252Fuploads%252FpvgLEoJ9HhHZGWSbXqAb%252Fezgif-1-4930d15e0c.gif%3Falt%3Dmedia%26token%3Dc0f7e559-2ff5-454f-8e3e-91fad31dfb37&width=768&dpr=4&quality=100&sign=92aab2ad&sv=1)

### 

[](#model-and-dataset-metrics)

Model and Dataset Metrics

The top of the Insights Panel displays aggregate model performance (default to F1 for NLP, Accuracy, mAP and IOU for Image Classification, Object Detection or Semantic Segmentation) and allow you to select between Precision, Recall, and F1. Additionally, the Insights Panel shows the number of current data samples in scope along with what % of the total data is represented.

![](https://docs.rungalileo.io/~gitbook/image?url=https%3A%2F%2F1924900477-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F4jVWiQpRqmi04OnqZmn2%252Fuploads%252FAtFBBJ1QxqJMQTJus59N%252Fimage.png%3Falt%3Dmedia%26token%3D59fb4a36-5a17-40ec-b232-984cfae52349&width=768&dpr=4&quality=100&sign=70b6562&sv=1)

### 

[](#class-level-model-performance)

Class Level Model Performance

Based on the model metric selected (F1, Precision, Recall), the "Model performance" bar chart displays class level model performance.

![](https://docs.rungalileo.io/~gitbook/image?url=https%3A%2F%2F1924900477-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F4jVWiQpRqmi04OnqZmn2%252Fuploads%252F5U5oCRNMMMN7pkDvbwbF%252FScreen%2520Shot%25202023-04-18%2520at%25209.53.04%2520PM.png%3Falt%3Dmedia%26token%3Dfd9adcb5-e992-48bf-95fc-1b28b0a560e2&width=768&dpr=4&quality=100&sign=12f0011a&sv=1)

Class Level Model Performance Chart

### 

[](#class-distribution)

Class Distribution

The Class Distribution chart shows the breakdown of samples within each class. This insights chart is critical for quickly drawing insights about the class makeup of the data in scope and for detecting issues with class imbalance.

![](https://docs.rungalileo.io/~gitbook/image?url=https%3A%2F%2F1924900477-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F4jVWiQpRqmi04OnqZmn2%252Fuploads%252FxN58O9rFsOW8N6Ep5j9v%252FScreen%2520Shot%25202023-04-18%2520at%25209.54.25%2520PM.png%3Falt%3Dmedia%26token%3D44f7fd7b-f8ac-47b3-8387-2f3c92c3518f&width=768&dpr=4&quality=100&sign=1801c241&sv=1)

Fig. Class Distribution plot

### 

[](#top-most-misclassified-pairs)

Top most misclassified pairs

At the bottom of the Insights Panel we show the "Top five 5 most misclassified data label pairs", where each pair shows a gold label, the incorrect prediction label, and the number of samples falling into this misclassified pairing. This insights chart provides a snapshot into the most common mistakes made by the model (i.e. mistaking ground truth label X for prediction label Y).

![](https://docs.rungalileo.io/~gitbook/image?url=https%3A%2F%2F1924900477-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F4jVWiQpRqmi04OnqZmn2%252Fuploads%252FNprmpTOshFyAAJnxHlSO%252FScreen%2520Shot%25202023-04-18%2520at%25209.55.14%2520PM.png%3Falt%3Dmedia%26token%3D5676fbf4-8e75-4398-a2c1-cf2e34990ed9&width=768&dpr=4&quality=100&sign=7ce0a24b&sv=1)

Fig. Top 5 misclassified label pairs - surfaces the most common mistakes made by the model

### 

[](#interacting-with-insights-charts)

Interacting with Insights Charts

In addition to providing visual insights, each insights chart can also be interacted with. Within the "Model performance", "Data Error Potential (DEP)", and "Class distribution" charts selecting one of the bars restricts the data in scope to data with <code class="py-[1px] px-1.5 min-w-[1.625rem] inline-flex justify-center items-center ring-1 ring-inset ring-dark/1 bg-dark/[0.06] rounded text-dark/8 dark:ring-light/1 dark:bg-light/1 dark:text-light/7 text-[.875em] leading-[calc(max(1.20em,1.25rem))]">Gold Label</code> equal to the selected <code class="py-[1px] px-1.5 min-w-[1.625rem] inline-flex justify-center items-center ring-1 ring-inset ring-dark/1 bg-dark/[0.06] rounded text-dark/8 dark:ring-light/1 dark:bg-light/1 dark:text-light/7 text-[.875em] leading-[calc(max(1.20em,1.25rem))]">bar label</code>.

An even more powerful interaction exists in the "Top 5 most misclassified label pairs" panel. Clicking on a row within this insights chart filters for <i class="font-italic">misclassified data</i> matching the <code class="py-[1px] px-1.5 min-w-[1.625rem] inline-flex justify-center items-center ring-1 ring-inset ring-dark/1 bg-dark/[0.06] rounded text-dark/8 dark:ring-light/1 dark:bg-light/1 dark:text-light/7 text-[.875em] leading-[calc(max(1.20em,1.25rem))]">gold label</code> and <code class="py-[1px] px-1.5 min-w-[1.625rem] inline-flex justify-center items-center ring-1 ring-inset ring-dark/1 bg-dark/[0.06] rounded text-dark/8 dark:ring-light/1 dark:bg-light/1 dark:text-light/7 text-[.875em] leading-[calc(max(1.20em,1.25rem))]">prediction label</code> of the misclassified label pair.

![](https://docs.rungalileo.io/~gitbook/image?url=https%3A%2F%2F1924900477-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F4jVWiQpRqmi04OnqZmn2%252Fuploads%252FgKZFjDe6G5lOz0gy78ZJ%252Fezgif.com-video-to-gif%2520%282%29.gif%3Falt%3Dmedia%26token%3Dd73da3d0-bd50-49ad-956b-4b0e60096eb5&width=768&dpr=4&quality=100&sign=c095412d&sv=1)

Fig. Interaction with "Most misclassified label pairs" chart allows for quick dataset filtering

[PreviousEmbeddings View](/galileo/how-to-and-faq/galileo-product-features/embeddings-view)[NextAlerts](/galileo/how-to-and-faq/galileo-product-features/xray-insights)

Last updated 1 year ago